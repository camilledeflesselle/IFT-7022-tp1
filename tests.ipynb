{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TÂCHE 1 – EXPRESSIONS RÉGULIÈRES – EXTRACTION D’INFORMATION À PARTIR DE RECETTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/camilledeflesselle/Desktop/IFT-7022/IFT-7022-tp1/fichiers_tp1\n"
     ]
    }
   ],
   "source": [
    "%cd fichiers_tp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture des ingrédients du fichier ./data/ingredients.txt. Voici quelques exemples: \n",
      "\n",
      "Extractions fausses :\n",
      "Result / Truth\n",
      "crème % / crème 35%\n",
      "poitrine de poulet désossées et / poitrine de poulet\n",
      "pommes de terre rattes / pommes de terre\n",
      "Préparation de la pâte épicée / \n",
      "sel et poivre du moulin  / sel et poivre du moulin\n",
      "Beurre pour fonçage / Beurre\n",
      "Le jus d’-lime / lime\n",
      "Percentage of errors for quantities : 8.59375%\n",
      "Percentage of errors for ingredients : 5.46875%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# (\\(?[\\d]+((,|\\/)[\\d]+)?\\s((c\\.|cuillère)s?\\sà\\s[A-zÀ-ü]+\\.?|(rôti\\sde|tasse|Bouquet|Rondelle|enveloppe|tranche)s?|m|g|k|po|lb|l|L|oz|)+(\\.|é|\\b)\\)?)\n",
    "execfile(\"t1_extraction_ingredients.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TÂCHE 2 – MODÈLES DE LANGUE N-GRAMMES - COMME LE DISAIT LE PROVERBE…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# télécharger nltk -> pip install nltk ->run la cellule\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test si nltk data téléchargé\n",
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre de proverbes pour entraîner les modèles :  3108\n",
      "\n",
      "\tProverbe incomplet: a beau *** qui vient de loin , Options: ['mentir', 'prêcher', 'temps', 'visage']\n",
      "\tSolution = a beau temps qui vient de loin , Valeur = 327.68151952835603\n",
      "\n",
      "\tProverbe incomplet: l’occasion fait le *** , Options: ['larron', 'malin', 'bonheur', 'pouvoir']\n",
      "\tSolution = l’occasion fait le bonheur , Valeur = 273.32276484035833\n",
      "\n",
      "\tProverbe incomplet: aide-toi, le ciel t’*** , Options: ['aidera', 'a', 'en', 'armera']\n",
      "\tSolution = aide-toi, le ciel t’a , Valeur = 301.3954347743886\n",
      "\n",
      "\tProverbe incomplet: année de gelée, *** de blé , Options: ['année', 'faute', 'années', 'et']\n",
      "\tSolution = année de gelée, et de blé , Valeur = 390.01718490193497\n",
      "\n",
      " Exactitude avec n = 1 et le critère 'perplexity' : 0.2391304347826087\n",
      "\n",
      "\tProverbe incomplet: a beau *** qui vient de loin , Options: ['mentir', 'prêcher', 'temps', 'visage']\n",
      "\tSolution = a beau temps qui vient de loin , Valeur = -58.49305350225498\n",
      "\n",
      "\tProverbe incomplet: l’occasion fait le *** , Options: ['larron', 'malin', 'bonheur', 'pouvoir']\n",
      "\tSolution = l’occasion fait le bonheur , Valeur = -48.56677089352377\n",
      "\n",
      "\tProverbe incomplet: aide-toi, le ciel t’*** , Options: ['aidera', 'a', 'en', 'armera']\n",
      "\tSolution = aide-toi, le ciel t’a , Valeur = -57.64859628098911\n",
      "\n",
      "\tProverbe incomplet: année de gelée, *** de blé , Options: ['année', 'faute', 'années', 'et']\n",
      "\tSolution = année de gelée, et de blé , Valeur = -60.251757181339876\n",
      "\n",
      " Exactitude avec n = 1 et le critère 'logprob' : 0.2391304347826087\n",
      "\n",
      "\tProverbe incomplet: a beau *** qui vient de loin , Options: ['mentir', 'prêcher', 'temps', 'visage']\n",
      "\tSolution = a beau temps qui vient de loin , Valeur = 1192.898700326167\n",
      "\n",
      "\tProverbe incomplet: l’occasion fait le *** , Options: ['larron', 'malin', 'bonheur', 'pouvoir']\n",
      "\tSolution = l’occasion fait le bonheur , Valeur = 364.8245246304567\n",
      "\n",
      "\tProverbe incomplet: aide-toi, le ciel t’*** , Options: ['aidera', 'a', 'en', 'armera']\n",
      "\tSolution = aide-toi, le ciel t’a , Valeur = 442.498038162677\n",
      "\n",
      "\tProverbe incomplet: année de gelée, *** de blé , Options: ['année', 'faute', 'années', 'et']\n",
      "\tSolution = année de gelée, et de blé , Valeur = 646.8734363337387\n",
      "\n",
      " Exactitude avec n = 2 et le critère 'perplexity' : 0.5\n",
      "\n",
      "\tProverbe incomplet: a beau *** qui vient de loin , Options: ['mentir', 'prêcher', 'temps', 'visage']\n",
      "\tSolution = a beau temps qui vient de loin , Valeur = -61.32153492471893\n",
      "\n",
      "\tProverbe incomplet: l’occasion fait le *** , Options: ['larron', 'malin', 'bonheur', 'pouvoir']\n",
      "\tSolution = l’occasion fait le bonheur , Valeur = -42.55529452475154\n",
      "\n",
      "\tProverbe incomplet: aide-toi, le ciel t’*** , Options: ['aidera', 'a', 'en', 'armera']\n",
      "\tSolution = aide-toi, le ciel t’a , Valeur = -52.737163492340784\n",
      "\n",
      "\tProverbe incomplet: année de gelée, *** de blé , Options: ['année', 'faute', 'années', 'et']\n",
      "\tSolution = année de gelée, et de blé , Valeur = -56.024037959388885\n",
      "\n",
      " Exactitude avec n = 2 et le critère 'logprob' : 0.5\n",
      "\n",
      "\tProverbe incomplet: aide-toi, le ciel t’*** , Options: ['aidera', 'a', 'en', 'armera']\n",
      "\tSolution = aide-toi, le ciel t’en , Valeur = 1801.4973065309157\n",
      "\n",
      "\tProverbe incomplet: ce n’est pas tous les jours *** , Options: ['fête', 'pâques', 'dangereux', 'noces']\n",
      "\tSolution = ce n’est pas tous les jours fête , Valeur = 424.78292287691187\n",
      "\n",
      "\tProverbe incomplet: à qui dieu aide, *** ne peut nuire , Options: ['nul', 'on', 'qui', 'rien']\n",
      "\tSolution = à qui dieu aide, on ne peut nuire , Valeur = 1453.2411525058822\n",
      "\n",
      "\tProverbe incomplet: il n’y a *** de rose de cent jours , Options: ['point', 'pas', 'rien', 'toujours']\n",
      "\tSolution = il n’y a pas de rose de cent jours , Valeur = 426.3212829967723\n",
      "\n",
      " Exactitude avec n = 3 et le critère 'perplexity' : 0.8913043478260869\n",
      "\n",
      "\tProverbe incomplet: aide-toi, le ciel t’*** , Options: ['aidera', 'a', 'en', 'armera']\n",
      "\tSolution = aide-toi, le ciel t’en , Valeur = -54.074903897073185\n",
      "\n",
      "\tProverbe incomplet: ce n’est pas tous les jours *** , Options: ['fête', 'pâques', 'dangereux', 'noces']\n",
      "\tSolution = ce n’est pas tous les jours fête , Valeur = -61.11407370499545\n",
      "\n",
      "\tProverbe incomplet: à qui dieu aide, *** ne peut nuire , Options: ['nul', 'on', 'qui', 'rien']\n",
      "\tSolution = à qui dieu aide, on ne peut nuire , Valeur = -73.53540886979286\n",
      "\n",
      "\tProverbe incomplet: il n’y a *** de rose de cent jours , Options: ['point', 'pas', 'rien', 'toujours']\n",
      "\tSolution = il n’y a pas de rose de cent jours , Valeur = -78.62217542752143\n",
      "\n",
      " Exactitude avec n = 3 et le critère 'logprob' : 0.8913043478260869\n",
      "\n",
      "\tProverbe incomplet: ce n’est pas tous les jours *** , Options: ['fête', 'pâques', 'dangereux', 'noces']\n",
      "\tSolution = ce n’est pas tous les jours fête , Valeur = 786.3661725235031\n",
      "\n",
      "\tProverbe incomplet: il n’y a *** de rose de cent jours , Options: ['point', 'pas', 'rien', 'toujours']\n",
      "\tSolution = il n’y a pas de rose de cent jours , Valeur = 672.7258661676785\n",
      "\n",
      "\tProverbe incomplet: on ne *** pas le poisson qui est encore dans la mer , Options: ['vend', 'prend', 'connaît', 'perd']\n",
      "\tSolution = on ne perd pas le poisson qui est encore dans la mer , Valeur = 2207.586092645389\n",
      "\n",
      " Exactitude avec n = 4 et le critère 'perplexity' : 0.9347826086956522\n",
      "\n",
      "\tProverbe incomplet: ce n’est pas tous les jours *** , Options: ['fête', 'pâques', 'dangereux', 'noces']\n",
      "\tSolution = ce n’est pas tous les jours fête , Valeur = -57.714344710258544\n",
      "\n",
      "\tProverbe incomplet: il n’y a *** de rose de cent jours , Options: ['point', 'pas', 'rien', 'toujours']\n",
      "\tSolution = il n’y a pas de rose de cent jours , Valeur = -75.1509993626441\n",
      "\n",
      "\tProverbe incomplet: on ne *** pas le poisson qui est encore dans la mer , Options: ['vend', 'prend', 'connaît', 'perd']\n",
      "\tSolution = on ne perd pas le poisson qui est encore dans la mer , Valeur = -99.97428587976266\n",
      "\n",
      " Exactitude avec n = 4 et le critère 'logprob' : 0.9347826086956522\n"
     ]
    }
   ],
   "source": [
    "execfile(\"t2_completer_proverbes.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TÂCHE 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naif bayes / word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots les plus importants pour la classe pos\n",
      "            Mots   neg   pos  pos - neg\n",
      "15250  excellent -8.16 -6.73       1.43\n",
      "47595  wonderful -8.24 -6.96       1.27\n",
      "34270      quiet -8.69 -7.46       1.23\n",
      "20307     highly -8.58 -7.41       1.18\n",
      "31652    perfect -8.18 -7.01       1.17\n",
      "20105    helpful -8.08 -7.20       0.88\n",
      "4504   beautiful -7.84 -7.06       0.78\n",
      "46743        war -8.22 -7.48       0.74\n",
      "27916     modern -8.23 -7.50       0.72\n",
      "46668       walk -7.57 -6.85       0.72\n",
      "Mots les plus importants pour la classe neg\n",
      "           Mots   neg   pos  pos - neg\n",
      "46827     waste -7.72 -9.83      -2.10\n",
      "47731     worst -7.04 -9.04      -1.99\n",
      "42886  terrible -7.53 -9.36      -1.82\n",
      "5717     boring -7.32 -9.11      -1.80\n",
      "41409    stupid -7.68 -9.19      -1.51\n",
      "47722     worse -7.59 -8.89      -1.30\n",
      "32720      poor -7.34 -8.59      -1.25\n",
      "3263      asked -7.45 -8.61      -1.17\n",
      "41867  supposed -7.53 -8.70      -1.17\n",
      "3933        bad -5.96 -7.09      -1.12\n",
      "Résultats avec la méthode NB / words :\n",
      "Accuracy - entraînement:  0.8151666666666667\n",
      "Accuracy - test:  0.8155487804878049\n",
      "Matrice de confusion:  [[801 181]\n",
      " [182 804]]\n",
      "\n",
      "Temps d'exécution de train_and_test_classifier : 4.168335325999578\n"
     ]
    }
   ],
   "source": [
    "model = 'NB'\n",
    "normalization = 'words'\n",
    "execfile(\"t3_analyse_sentiment.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naif bayes / lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film', 'good', 'hotel', 'like', 'movie', 'make', 'time', 'great', 'book', 'just', 'character', 'room', 'story', 'love', 'life', 'way', 'play', 'come', 'work', 'know', 'stay', 'year', 'scene', 'really', 'say', 'man', 'song', 'look', 'little', 'day']\n",
      "['film', 'movie', 'like', 'hotel', 'make', 'good', 'book', 'just', 'room', 'time', 'bad', 'character', 'say', 'look', 'know', 'think', 'come', 'stay', 'really', 'work', 'way', 'scene', 'play', 'thing', 'people', 'try', 'story', 'night', 'want', 'great']\n",
      "Résultats avec la méthode NB / lemma :\n",
      "Accuracy - entraînement:  0.8181666666666667\n",
      "Accuracy - test:  0.8119918699186992\n",
      "Matrice de confusion:  [[801 181]\n",
      " [189 797]]\n",
      "\n",
      "Temps d'exécution de train_and_test_classifier : 494.56697221399963\n"
     ]
    }
   ],
   "source": [
    "model = 'NB'\n",
    "normalization = 'lemma'\n",
    "execfile(\"t3_analyse_sentiment.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    }
   ],
   "source": [
    "analyzer_en = spacy.load(\"en_core_web_sm\")  \n",
    "x = \"i'm a really good person\"\n",
    "doc = analyzer_en(x)\n",
    "for token in doc:\n",
    "    if token.pos_ == 'ADJ':\n",
    "        print(token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naif bayes / stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thi', 'wa', 'hi', 'film', 'ha', 'veri', 'hotel', 'like', 'movi', 'good', 'time', 'book', 'just', 'make', 'great', 'charact', 'room', 'onli', 'love', 'doe', 'stori', 'way', 'play', 'best', 'work', 'stay', 'year', 'life', 'scene', 'realli']\n",
      "['thi', 'wa', 'hi', 'film', 'movi', 'like', 'hotel', 'book', 'ha', 'just', 'room', 'good', 'onli', 'veri', 'time', 'make', 'charact', 'doe', 'did', 'look', 'becaus', 'ani', 'work', 'bad', 'stay', 'realli', 'way', 'play', 'scene', 'know']\n",
      "Résultats avec la méthode NB / stem :\n",
      "Accuracy - entraînement:  0.8163333333333332\n",
      "Accuracy - test:  0.8109756097560976\n",
      "Matrice de confusion:  [[811 171]\n",
      " [201 785]]\n",
      "\n",
      "Temps d'exécution de train_and_test_classifier : 76.15429242299979\n"
     ]
    }
   ],
   "source": [
    "model = 'NB'\n",
    "normalization = 'stem'\n",
    "execfile(\"t3_analyse_sentiment.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reg Log / words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots les plus importants pour la classe pos\n",
      "             Mots   pos\n",
      "42891    terrific  2.71\n",
      "554            41  2.30\n",
      "2115       allows  2.20\n",
      "39776     sofitel  2.00\n",
      "33534  profession  1.80\n",
      "36137  revolution  1.76\n",
      "28345       moves  1.68\n",
      "29158      nicely  1.65\n",
      "31652     perfect  1.63\n",
      "24477  laserlight  1.60\n",
      "Mots les plus importants pour la classe neg\n",
      "                Mots   pos\n",
      "12390  disappointing -3.46\n",
      "46828         wasted -2.77\n",
      "46827          waste -2.68\n",
      "3800           awful -2.64\n",
      "11757     depressing -2.57\n",
      "5717          boring -2.39\n",
      "42886       terrible -2.23\n",
      "36269     ridiculous -2.20\n",
      "47731          worst -2.12\n",
      "13444           drum -1.99\n",
      "Résultats avec la méthode LR / words :\n",
      "Accuracy - entraînement:  0.8135\n",
      "Accuracy - test:  0.8241869918699187\n",
      "Matrice de confusion:  [[805 177]\n",
      " [169 817]]\n",
      "\n",
      "Temps d'exécution de train_and_test_classifier : 8.19931611299944\n"
     ]
    }
   ],
   "source": [
    "model = 'LR'\n",
    "normalization = 'words'\n",
    "execfile(\"t3_analyse_sentiment.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reg Log / Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats avec la méthode LR / stem :\n",
      "Accuracy - entraînement:  0.8411666666666665\n",
      "Accuracy - test:  0.8353658536585366\n",
      "Matrice de confusion:  [[825 157]\n",
      " [167 819]]\n",
      "\n",
      "Temps d'exécution de train_and_test_classifier : 174.15462321199993\n"
     ]
    }
   ],
   "source": [
    "model = 'LR'\n",
    "normalization = 'stem'\n",
    "execfile(\"t3_analyse_sentiment.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reg Log / Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats avec la méthode LR / lemma :\n",
      "Accuracy - entraînement:  0.8338333333333333\n",
      "Accuracy - test:  0.8440040650406504\n",
      "Matrice de confusion:  [[833 149]\n",
      " [158 828]]\n",
      "\n",
      "Temps d'exécution de train_and_test_classifier : 595.7705179699988\n"
     ]
    }
   ],
   "source": [
    "model = 'LR'\n",
    "normalization = 'lemma'\n",
    "execfile(\"t3_analyse_sentiment.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tache 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 18 langues d'origine sont: \n",
      "['Czech', 'German', 'Arabic', 'Japanese', 'Chinese', 'Vietnamese', 'Russian', 'French', 'Irish', 'English', 'Spanish', 'Greek', 'Italian', 'Portuguese', 'Scottish', 'Dutch', 'Korean', 'Polish']\n",
      "\n",
      "Quelques noms chinois : \n",
      " ['Ang', 'AuYong', 'Bai', 'Ban', 'Bao', 'Bei', 'Bian', 'Bui', 'Cai', 'Cao', 'Cen', 'Chai', 'Chaim', 'Chan', 'Chang', 'Chao', 'Che', 'Chen', 'Cheng', 'Cheung']\n",
      "\n",
      "Accuracy pour NB / 1-gram = 0.16111111111111112\n",
      "\n",
      "Accuracy pour NB / 2-gram = 0.4\n",
      "\n",
      "Accuracy pour NB / 3-gram = 0.37777777777777777\n",
      "\n",
      "Accuracy pour NB / multi-gram = 0.3055555555555556\n",
      "\n",
      "Accuracy pour LR / 1-gram = 0.25555555555555554\n",
      "\n",
      "Accuracy pour LR / 2-gram = 0.5333333333333333\n",
      "\n",
      "Accuracy pour LR / 3-gram = 0.5222222222222223\n",
      "\n",
      "Accuracy pour LR / multi-gram = 0.6388888888888888\n"
     ]
    }
   ],
   "source": [
    "execfile(\"t4_classification_noms.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
