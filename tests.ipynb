{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TÂCHE 1 – EXPRESSIONS RÉGULIÈRES – EXTRACTION D’INFORMATION À PARTIR DE RECETTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/camilledeflesselle/Desktop/IFT-7022/IFT-7022-tp1/fichiers_tp1\n"
     ]
    }
   ],
   "source": [
    "%cd fichiers_tp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture des ingrédients du fichier ./data/ingredients.txt. Voici quelques exemples: \n",
      "\n",
      "Extractions fausses :\n",
      "Result / Truth\n",
      "pommes vertes pelées / pommes vertes\n",
      "échalotes coupées finement / échalotes\n",
      "champignons émincés / champignons\n",
      "crème % / crème 35%\n",
      "poitrine de poulet désossées et coupées / poitrine de poulet\n",
      "oeuf battu / oeuf\n",
      "gingembre râpé / gingembre\n",
      "oignon vert coupés / oignon vert\n",
      "fromage cheddar râpé / fromage cheddar\n",
      "échalote hachées / échalote\n",
      "oeuf battu / oeuf\n",
      "pommes de terre rattes coupées(¼ po) d’épaisseur / pommes de terre\n",
      "Préparation de la pâte épicée / \n",
      "cacahuètes torréfiées / cacahuètes\n",
      "petites palourdes dans leur coquille / petites palourdes\n",
      "langoustines surgelées et décongelées (voir note) / langoustines surgelées\n",
      "asperges moyennes coupées / asperges moyennes\n",
      "persil plat ciselé / persil plat\n",
      "pain baguette d’environ  cm d’épaisseur / pain baguette\n",
      "Beurre pour fonçage / Beurre\n",
      "Percentage of errors for quantities : 12.5%\n",
      "Percentage of errors for ingredients : 15.625%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# (\\(?[\\d]+((,|\\/)[\\d]+)?\\s((c\\.|cuillère)s?\\sà\\s[A-zÀ-ü]+\\.?|(rôti\\sde|tasse|Bouquet|Rondelle|enveloppe|tranche)s?|m|g|k|po|lb|l|L|oz|)+(\\.|é|\\b)\\)?)\n",
    "execfile(\"t1_extraction_ingredients.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TÂCHE 2 – MODÈLES DE LANGUE N-GRAMMES - COMME LE DISAIT LE PROVERBE…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# télécharger nltk -> pip install nltk ->run la cellule\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test si nltk data téléchargé\n",
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre de proverbes pour entraîner les modèles :  3108\n"
     ]
    }
   ],
   "source": [
    "execfile(\"t2_completer_proverbes.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TÂCHE 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des partitions du jeu de données\n",
      "\ttrain_pos_fn : 3000\n",
      "\ttrain_neg_fn : 3000\n",
      "\ttest_pos_fn : 986\n",
      "\ttest_neg_fn : 982\n",
      "\n",
      "Numbre d'attributs de classification :  48616\n",
      "Type de classificateur :  MultinomialNB()\n",
      "logprob(neg) = -0.69\n",
      "logprob(pos) = -0.69\n",
      "Accuracy - entraînement:  0.9493333333333334\n",
      "Accuracy - test:  0.8114837398373984\n",
      "Matrice de confusion:  [[828 154]\n",
      " [217 769]]\n"
     ]
    }
   ],
   "source": [
    "execfile(\"t3_analyse_sentiment.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
